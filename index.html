<!doctype html>
<html lang="fr">
<head>
<meta charset="utf-8">
<title>BytePacking</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<style>

:root {
	--back-color: rgb(255, 247, 211);
	--text-color: rgb(12, 12, 12);
	--url-color:rgb(120, 120, 120);
}

/* minimalist reset */
* {
	padding: 0;
	margin: 0;
	font-size: 1em;
}

body {
	background-color: var(--back-color);
	color: var(--text-color);
	font-family: Tahoma, Verdana, Arial, sans-serif;
}

main {
	margin: 0 auto;
	padding: 30px 140px 0 140px;
	max-width: 600px;
	min-height: 100vh;
}

h1 {
	font-size: 1.5em;
	font-weight: 700;
	display: inline;
	margin-right: 5px;
}
h2 {
	font-weight: 400;
	margin-top: 0px;
}
h3 {
	font-weight: 400;
	margin-bottom: 30px;
}

footer {
	text-align: right;
	margin-top: 80px;
	padding-bottom: 20px;
}

p {
	line-height: 1.5em;
	margin-top: 20px;
	display: block;
}

a {
	color: inherit;
	word-wrap: break-word;
	overflow-wrap: break-word;
}
a:hover, a:focus {
	color: var(--url-color);
}
code {
  font-size: 1.1em;
}
pre {
	overflow-x: auto;
	white-space: pre-wrap;
	word-wrap: break-word;
}

ol {
    counter-reset: item;
}
ol>li {
    counter-increment: item;
    list-style: none inside;
    margin: 20px 0;
    overflow: hidden;
    line-height: 1.5em;
}
ol>li:before {
    content: counter(item) ;
    margin-right: 10px;
    padding: 8px;
    border-radius: 50%;
    width: 25px;
    background: var(--text-color);
    color: var(--back-color);
    text-align: center;
    float: left;
    font-weight: 700;
}

@media (max-width: 600px) {
  main {
  	max-width: 100%;
    padding: 20px 15px;
  }
  h2 {
    font-size: 1.3em;
    margin-top: 30px;
  }
}

</style>
</head>
<body>

<main>
<h1>Paradis artificiels</h1>
<h2><i>Expérimentations iaesques d'un traducteur geek</i></h2>

<p><b>2025-10-24</b></p>
<p>Je demande à Gemini de réparer mon appli sur Google AI Studio et fais un essai avec un fichier complet. Mon "proofreader" détecte 130 changements, que je dois passer en revue un par un avant de l'accepter ou de le refuser. L'outil détecte un certain nombre de faux positifs quand il s'agit des majuscules ou minuscules. Je le modifie pour améliorer ce point et demande l'ajout d'un bouton pour accepter tous les changements d'un coup. Ça fonctionne.</p>
<p>Découverte du projet marimo (<a href="https://github.com/marimo-team/marimo),">https://github.com/marimo-team/marimo),</a> sorte de jupyter notebooks on steroids super prometteur.</p>
<p>Première tentative de "git push" en ligne de commande (avec une image)</p>
<p><pre><code>$ git clone https://github.com/sebington/sebington.github.io.git
$ cd sebington.github.io/
$ git add images/nn.png
$ git commit -m "Add image to images folder"
$ git push origin main [provide Username and Passward]</code></pre></p>
<p>Pour renommer un fichier</p>
<p><pre><code>$ git mv index.html index_old.html
$ git commit -m "Rename index.html"
$ git push origin main</code></pre></p>
<p><b>2025-10-23</b></p>
<p>Simon Willison, probablement à la demande d'Anthropic, a supprimé de son Github les fichiers "Claude Skills" qu'il avait découverts et téléchargés avant l'annonce officielle d'Anthropic concernant ce nouveau service de Claude (<a href="https://simonwillison.net/2025/Oct/10/claude-skills/).">https://simonwillison.net/2025/Oct/10/claude-skills/).</a></p>
<p>Nouvelle session Gemini CLI. Je lui demande d'utiliser les "Claude Skills" pour réviser un document Word et le livrer en mode suivi des modifications. J'oublie toujours d'activer le projet avec uv avant de commencer !</p>
<p>Prompt: <code>Do a professional revision (grammar, spelling, punctuation etc.) of @test.docx and output a .docx file in tracking mode where all the changes made are visible.</code></p>
<p>En parallèle je demande à Claude Sonnet 4.5 de faire la même chose dans l'interface web "classique".</p>
<p>Gemini bosse comme un dingue et grille son quota de tokens avant d'avoir terminé.</p>
<p>Claude crée une interface web inutile et ne parvient pas à sortir un document Word (erreur). Je le relance et il finit par me donner le résultat sous forme d'un fichier TXT avec les corrections (surtout l'orthographe) demandées.</p>
<p>Nouvelle tentative : je crée une appli sur Google AI Studio qui fonctionne du premier coup, prend un .docx, le révise, me montre les changements apportés et produit un document Word en mode suivi des modification. Le délire. Mais est-ce que ça marcherait avec un gros fichier ? Je retourne sur l'appli 3h plus tard et bizarrement le code est toujours là mais l'interface graphique ne se charge pas. Ecran noir.</p>
<p>Retour sur Manjaro Gnome. Je règle tous les problèmes rencontrés hier et savoure cette nouvelle distro qui est vraiment sympa.</p>
<p>Je suis un tuto de Simon Willison (<a href="https://www.youtube.com/watch?v=5TdIxxBPUSI).">https://www.youtube.com/watch?v=5TdIxxBPUSI).</a> Pas très progressif et un peu fouilli mais instructif. Je crée un projet 'sqlite' avec uv et ipykernel et lance un jupyter notebook où je tape les exemples de code. Tout fonctionne bien et je peux sauvegarder les sorties.</p>
<p>L'infatiguable Willison vient de mettre une nouvelle vidéo en ligne (<a href="https://www.youtube.com/watch?v=GQvMLLrFPVI&list=WL)">https://www.youtube.com/watch?v=GQvMLLrFPVI&list=WL)</a> dans laquelle il utilise Claude Code Web pour se fabriquer un outil à partir de 2 autres outils créés précédemment. On aperçoit au passage l'impressionnante collection d'outils dont il dispose et qui sont disponibles sur son github (<a href="https://tools.simonwillison.net/).">https://tools.simonwillison.net/).</a></p>
<p><b>2025-10-22</b></p>
<p>Avec Claude, je continue de modifier mon script de génération de HTML à partir de mes notes au format TXT (voir 19/10). Ça commence à devenir pas mal.</p>
<p>Je télécharge Linux Mint Cinnamon, l'installe sur une clé USB bootable avec Rufus et l'utilise pendant 30 minutes. Je trouve bien mes marques. Le terminal est imparamétrable une fois de plus et j'installe le terminal émulé "deepin" à la place. Plutôt pas mal.</p>
<p><b>2025-10-21</b></p>
<p>J'installe Manjaro Gnome pour voir. Pas mal de positif (look, rapidité, efficacité) mais certaines choses bizarres comme par exemple le fait que je n'arrive pas à lancer un outil installé dans uv et que je ne peux pas complètement désinstaller zsh, qui semble étroitement intégré à l'OS (dépendances). Le terminal pré-installé n'est pas paramétrable et j'en installe une autre version. En revanche, Nextcloud, Signal et OBS Studio fonctionnent à merveille.</p>
<p>Retour dans Ubuntu</p>
<p>Commande pour n'afficher que les modèles gratuits d'openrouter dans LLM:</p>
<p><pre><code>llm models | grep ':free$'</code></pre></p>
<p>J'installe <a href="https://datasette.io/">https://datasette.io/</a> avec uv</p>
<p><pre><code>uv tool install datasette
llm models | grep ':free$'
llm -m openrouter/google/gemma-3-27b-it:free "What is Datasette?"
datasette "$(llm logs path)"</code></pre></p>
<p>cela donne l'accès à une interface web</p>
<p><pre><code>INFO:     Started server process [13667]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8001 (Press CTRL+C to quit)</code></pre></p>
<p>où on peut requêter la base de données de tout l'historique de LLM (prompts, modèles, réponses, etc.)</p>
<p><b>2025-10-20</b></p>
<p>Je visionne une vidéo YT [C44iCr6czAo] sur les dérives sécuritaires de Windows. Ça me donne envie de basculer sur Linux et d'y rester. Je télécharge 2 versions de Manjaro (KDE Plasma et Gnome) ainsi que CachyOS, que je teste tour à tour. Moi qui m'étais promis de me reposer les yeux ce soir, c'est raté.</p>
<p><b>2025-10-19</b></p>
<p>Je demande à Claude de me créer un script en Python (logbook-converter) qui convertit ce carnet de notes en fichier HTML avec les prompts et les extraits de code reconnus et formattés. Work in progress (à suivre).</p>
<p>Je n'en finis pas de peaufiner le projet youtube metadata (1. retrieve, 2. analyze). Le fichier 'source' est une liste de chaines YT au format CSV (export de FreeTube), le fichier intermédiaire est un fichier JSON (channel_videos_2025.json) et la sortie finale peut se faire soit à l'écran (v2), soit écran + markdown (v2_md). Je finis par faire une vidéo.</p>
<p>Je continue d'essayer de construire un plugin Hugging Face pour Willison's LLM avec Gemini-CLI. C'est de la folie pure de s'attaquer à un truc pareil. Je vais néanmoins beaucoup plus loin qu'hier. Le plugin s'installe et récupère une liste de modèles. Cependant impossible de lancer une requête (Error: Client error '404 Not Found' for url '<a href="https://router.huggingface.co/v1/chat/completions').">https://router.huggingface.co/v1/chat/completions').</a></p>
<p><b>2025-10-18</b></p>
<p>J'active Copilot dans VScode et le teste timidement. Copilot n'a pas compris que j'utilise uv et tente d'installer des librairies Python avec pip sur Ubuntu. Je l'arrête et y reviendrai dès que possible.</p>
<p>Suite à la découverte du nouveau HuggingChat il y a 2 jours, je me dis qu'il est probable que HF essaie de proposer quelque chose comme OpenRouter : une seule API donne accès à de nombreux modèles. Je pose la question à ChatGPT qui finit par me le confirmer après être allé lire la doc de HF "en direct".</p>
<p>Conclusion de ChatGPT :<br><code>Yes, Hugging Face is now offering a multi-provider inference capability via its Inference Providers framework that approximates the “one API, many models/providers” goal. The OpenAI-compatible API support is a particularly strong move, en"abling you to reuse existing client libraries against HF’s routing system.</code></p>
<p>Convaincu par cette explication, je me dis qu'en théorie, je pourrais créer un plugin pour Willison's LLM qui donnerait accès aux modèles de HF. Mais je me dis que c'est peut-être un peu trop ambitieux de commencer par ça. Essayons déjà de voir si l'API de HF fonctionne comme prévu.</p>
<p>Je me rends sur <a href="https://huggingface.co/docs/inference-providers/">https://huggingface.co/docs/inference-providers/</a> et finit par trouver un bout de code pour tester l'API. Il faut créer une clé spéciale (allowing inference providers). Le script fonctionne.</p>
<p>Je demande alors à Gemini-CLI d'incorporer HF aux 3 autres providers de mon script 2_analyze_gemini_v1.py (projet youtube).</p>
<p>Prompt : <code>Use @test_hf.py to add Hugging Face as a new model provider in @2_analyze_gemini_v2.py.</code></p>
<p>Gemini-CLI le fait en 2 temps 3 mouvements. C'est totalement jouissif. Je lui demande la possibilité de pouvoir revenir à la liste des "providers" si je ne choisis pas de modèle tout de suite. On peut ainsi comparer le nombre de modèles proposés par chaque provider : Mistral = 68, Groq = 19, OpenRouter = 340 et Hugging Face = 115.</p>
<p>Je fais une vidéo sous Linux avec OBS Studio qui fonctionne enfin !</p>
<p>Je tente tout de même de créer le plugin HF avec Gemini-CLI, mais n'arrive pas à l'installer dans LLM.</p>
<p><b>2025-10-16</b></p>
<p>Je tente d'utiliser nextcloud en ligne de commande avec WSL pour tester la vitesse de synchronisation des fichiers:</p>
<p><pre><code>mkdir nextcloud
sudo add-apt-repository ppa:nextcloud-devs/client
sudo apt update
sudo apt install nextcloud-client</code></pre></p>
<p>Mais c'est très galère : au lieu de spécifier quels dossiers on veut synchroniser, il faut exclure tous les dossiers que l'on ne veut PAS synchroniser</p>
<p><pre><code>--exclude "SEB" --exclude "TAO" etc.</code></pre></p>
<p>Du coup je désinstalle tout.</p>
<p>Je génère de nouveaux scripts dans mon projet youtube metadata :<br>- yt_metadata_csv.py (titre et upload date à partir de plusieurs chaines YT)<br>- retrieve_multiple_yt_video_titles.py (titre et upload date à partir de plusieurs videos)</p>
<p>Ce second script exporte le résultat du scraping de toutes mes URL de videos YT dans un fichier CSV (URL, Title, Upload date) que j'importe ensuite dans Google Drive. A noter que ce script n'utilise pas yt-dlp mais fait appel à requests et beautifulsoup4 et semble être plus rapide.</p>
<p>Le nouveau HuggingChat (<a href="https://huggingface.co/chat/)">https://huggingface.co/chat/)</a> est une tuerie (116 modèles proposés).</p>
<p>Simon Willison reparle des "Claude Skills" sur son blog. Je suis certain que ce que j'ai fait avec Claude Skills et Gemini-CLI le 12/10 n'avait jamais été fait auparavant.</p>
<p><b>2025-10-15</b></p>
<p>L'alignement manuel des textes de ma collègue est décidément impossible avec memoQ. Obsédé par le côté récalcitrant de la chose, je demande à Claude de me créer un outil d'alignement.</p>
<p><code>I have two .txt files source (fr) and target (en) that I would like to align in order to obtain a translation memory (.tmx). Create a Python script that will scan the two .txt files line by line (this is important), retrieve all sentences and expressions pairs (source and target language) and store them methodically and chronologically in a dictionary, to be later exported as a .tmx file. Keep everything, even if source text is the same as target text but remove duplicate entries. Discard section numbering (e.g. 12.2.3.1) at the start of a line. Discard lines containing just one letter or only numbers. Keep all meaningful chains of characters. Segment at sentence level whenever possible. Attached are two extracts (source and target).</code></p>
<p>Ça marche ! One shot !😃 Le script génère un fichier TMX valide que j'importe dans memoQ sans problème. Dingue.</p>
<p><a href="https://repomix.com/">https://repomix.com/</a> is a powerful tool that packs your entire repository into a single, AI-friendly file.<br><a href="https://www.kimi.com/en/">https://www.kimi.com/en/</a> : sounds like another great LLM like Qwen and DeepSeek</p>
<p><b>2025-10-14</b></p>
<p>Je fais une vidéo sur la tentative d'alignement de fichiers .txt avec memoQ et sur la nouvelle approche avec Gemini CLI du 12/10.</p>
<p>Il faut que je m'intéresse aux "MCP server".<br>Une liste impressionnante : <a href="https://github.com/modelcontextprotocol/servers">https://github.com/modelcontextprotocol/servers</a><br>Essayer celui-ci peut-être : <a href="https://github.com/vivekVells/mcp-pandoc">https://github.com/vivekVells/mcp-pandoc</a></p>
<p><b>2025-10-13</b></p>
<p>Ce soir, je me fais un petit shot de vidéos d'Underscore. Par exemple [biZX5cnQ_UU] dans lequel je découvre Grégoire Mialon et Clémentine Fourrier de Hugging Face, ou [s5oHvfFUsbE] avec un certain Nicolas Dufour. Je visite le site de Clémentine Fourrier dont j'adore le côté minimaliste (<a href="https://clefourrier.github.io/)">https://clefourrier.github.io/)</a> avec en bas, ce lien vers (<a href="https://jeffhuang.com/designed_to_last/),">https://jeffhuang.com/designed_to_last/),</a> au concept super intéressant. Je check le projet de Nicolas Dufour (un modèle de géolocalisation d'images) : <a href="https://nicolas-dufour.github.io/plonk.">https://nicolas-dufour.github.io/plonk.</a></p>
<p>Du coup je fais des essais de mise en ligne de ce carnet sur <a href="http://bytepacking.free.fr/.">http://bytepacking.free.fr/.</a> Du bon vieux html. Pour mettre la page en ligne, j'utilise un outil primitif fourni par free : <a href="http://ftpperso.free.fr/index.pl.">http://ftpperso.free.fr/index.pl.</a> J'installe un plugin (<a href="https://packagecontrol.io/packages/Simple%20FTP%20Deploy)">https://packagecontrol.io/packages/Simple%20FTP%20Deploy)</a> dans Sublime Text pour faciliter la chose, mais pour l'instant ne parviens pas m'en servir.</p>
<p>Liens du jour :<br>Pense-bête uv : <a href="https://mathspp.com/blog/uv-cheatsheet">https://mathspp.com/blog/uv-cheatsheet</a><br>Sortie de NanoChat d'Andrej Karphaty : <a href="https://github.com/karpathy/nanochat">https://github.com/karpathy/nanochat</a><br>Sauvegarder une session Gemini-CLI en markdown doit être possible : <a href="https://gist.github.com/simonw/12c7b072e8e21ef1e040fb3b69c1da28">https://gist.github.com/simonw/12c7b072e8e21ef1e040fb3b69c1da28</a></p>
<p><b>2025-10-12</b></p>
<p>Ce soir je me penche sur les outils de Claude (Claude Skills) pour manipuler les fichiers et fais un essai avec le répertoire dédié à Word (.docx). La "boite à outil" étant assez complexe, je décide de faire bosser Gemini CLI dessus (avec uv pour exécuter les scripts en Python). Après tout ces outils ont été conçus pour être piloté par une IA. L'objectif est de remplacer du texte FR par du texte EN dans un document Word (.docx) en le copiant d'un fichier à l'autre, sans altérer la structure (images) du fichier cible. Je fais 3 tentatives. Une session sur Windows, mal configurée, produit un fichier illisible. Mais les deux autres (sur Ubuntu) fonctionnent. Avec 2 fichiers très simples constitués de 4 paragraphes de texte et de 2 images en FR (et la même chose en EN), je demande à Gemini CLI de trouver un moyen de remplacer le texte du fichier en français par le texte du fichier en anglais, sans altérer la mise en page et les images.</p>
<p><code>Using the available tools in this project, devise a strategy to replace the text from @input-fr.docx by the text from @input-en.docx, keeping the layout and integrity of the target document.</code></p>
<p>Il s'exécute et produit un fichier cible où le texte en français a été remplacé par le texte en anglais. Mais comment être absolument certain qu'il n'a pas simplement copié le fichier source dans son intégralité ? Je fais une deuxième tentative plus ambitieuse : je ne laisse dans le répertoire de travail que le fichier Word FR, auquel j'ajoute le texte en anglais au format TXT. Je demande à Gemini CLI la même chose, c'est à dire de remplacer le texte en FR par le texte en EN, mais cette fois à partir du fichier TXT.</p>
<p><code>@input-fr.docx is a .docx of a short text in French with photos. @en-text.txt is a replacement text in English for the docx file. Use the tools provided here to edit @input-fr.docx and replace the text it contains by the text in @en-text.txt while keeping the photos.</code></p>
<p>Sans surprise, il n'y arrive pas. Je lui demande alors de faire une comparaison linguistique des contenus AVANT commencer l'opération et ça marche !</p>
<p><code>Use a linguistic approach and run a similarity search to check that the meaning of each paragraph in English of @en-text.txt corresponds approximately to the paragraph in French. If so then copy it over the French in the .docx file.</code></p>
<p>Il compare les textes, établit des correspondances entre les paragraphes et remplace le texte FR par le texte EN au bons endroits, sans toucher aux images ! 😃 Mais ce n'est qu'un début et les fichiers utilisés sont hyper simples.</p>
<p>A faire : complexifier les fichiers .docx (ajouter par ex. numérotation, gras, italiques)</p>
<p><b>2025-10-11</b></p>
<p>Je regarde <a href="https://www.youtube.com/watch?v=0OUODPRgPl8">https://www.youtube.com/watch?v=0OUODPRgPl8</a> (10+ Tools to Use AI in the Terminal) et prends des notes. Le gars aurait mieux fait d'intituler sa vidéo "Demo of Simon Willison's LLM"! Sur le même sujet, il y a aussi <a href="https://www.youtube.com/watch?v=UZ-9U1W0e4o">https://www.youtube.com/watch?v=UZ-9U1W0e4o</a></p>
<p>Je découvre un post de Simon Willison concernant les "Claude Skills", des outils de manipulation de fichiers de Claude que Simon a "hacké" à demi-mots "<code>This is a really sophisticated set of tools for document manipulation, and I love that Anthropic have made those visible - presumably deliberately - to users of Claude who know how to ask for them.</code>" (<a href="https://simonwillison.net/2025/Oct/10/claude-skills/).">https://simonwillison.net/2025/Oct/10/claude-skills/).</a> Super intéressant. Je télécharge le truc sur son Github et j'en parle à Olivier.</p>
<p><b>2025-10-09</b></p>
<p>Le problème de l'alignement automatique des textes pour le projet de ma collègue semble insoluble. Même si les résultats d'hier soir sont encourageants. Je tente de passer tout en .txt et compare dans notepad++. Même la numérotation des sections n'est pas fiable 😫</p>
<p><b>2025-10-08</b></p>
<p>Tentative de génération d'un script pour un outil d'alignement multilingue de textes "aligner" avec ChatGPT, Claude (script avec openrouter et mistral) puis Gemini CLI. De plus en plus je rencontre les limites des accès API "Free Tier". Est-ce voulu ? Bizarrerie : l'accès OpenRouter fonctionne pour mon script "analyze youtube metadata" mais pas avec "aligner openrouter". Je pose la question à ChatGPT qui me donne une explication et un patch, mais qui ne marche pas.</p>
<p>Je refile le bébé à Gemini CLI et le fait bosser sur plusieurs déclinaisons du script (il améliore la fonction embeddings) avec openrouter seul, puis avec ollama (embeddings) et openrouter (LLM), puis comme le free tier d'openrouter est grillé, avec "ollama only" (embeddinggemma et gemma3) et ça marche enfin sans erreurs ! Le résultat de l'alignement est stocké dans un fichier JSON. Le script est quand même assez long : 500+ lignes de code.</p>
<p>Je change mon mot de passe Google sur mon PC via le navigateur et je reçois une notification sur mon téléphone Xiaomi, alors que j'avais supprimé le compte Google du téléphone. Ça laisse songeur.</p>
<p><b>2025-10-07</b></p>
<p>Je fais le gros ménage dans mes scripts (YT metadata). Instructif. Inutile de garder des vieux scripts. Perte de temps.</p>
<p><b>2025-10-06</b></p>
<p>Vidéo pour Olivier (YT metadata) très mal préparée et décevante. Mais ça me fait avancer.</p>
<p><b>2025-10-05</b></p>
<p>Un effet particulièrement délétère de l'arrivée de l'IA dans les entreprises de services, c'est l'assomption par le client que la prestation est désormais exécutable en 2-3 clics de souris, que le devis qui lui est envoyé est surcoté et n'est pas le reflet du travail réellement effectué.</p>
<p>autoencoder mnist plan<br>1. after training do not run the test set<br>2. ask user to input a square image of a handwritten digit<br>3. normalize the image (size, color, bit depth) so that is complies with the train set<br>4. submit the image to the model<br>5. display the model's best guess</p>
<p>J'ai retesté llamafile sous windows (qwen3 et gemma3) et je trouve la génération plus rapide.</p>
<p>Ai fait une vidéo pour Olivier mais pas très satisfaisante (pas envoyée).</p>
<p>Ai testé Google Jules sur autoencoder hébergé sur Github. Bluffant.</p>
<p>Ai installé Gemini CLI sur Powershell, puis modifié autoencoder avec. Super bluffant.</p>
<p><b>2025-10-04</b></p>
<p>Nouvel instal de la version beta 25.10 d'Ubuntu. Elle propose un nouveau terminal par défaut (ptyxis) difficile à paramétrer. Je finis par réinstaller gnome-terminal. J'installe nextcloud et constate que la mise à jour des fichiers est à nouveau rapide. La DSI a peut-être résolu le problème de lenteur. Ce faisant j'oublie de sauvegarder les logs de Gemini CLI.</p>
<p>Je consulte ma ai_bookmarks.txt list un peu au hasard, consulte le site de Fabrice Bellard (<a href="https://bellard.org)">https://bellard.org)</a> et c'est parti pour un petit voyage technologique passionnant.<br>Je télécharge son projet /tsac/ et le teste avec un mp3 de piano (renommé toto.mp3) dans powershell :</p>
<p><pre><code>./tsac c toto.mp3 toto.tsac</code></pre></p>
<p>Le fichier passe de 4707 KB à 101 KB !</p>
<p><pre><code>./tsac d toto.tsac toto.wav</code></pre></p>
<p>Le fichier .wav fait 25 931 KB et je ne détecte pas de perte de qualité sonore !</p>
<p>Je demande des explications à Claude concernant le rôle du Transformer (voir "Ultra-low bitrate audio compression") :</p>
<p>The Transformer model acts as a learned compressor on top of the DAC encoding. Here's what it does:<br>Input: Takes the discrete codes/tokens produced by the DAC encoder<br>Function: Finds patterns and redundancies in these codes to represent them more efficiently<br>Output: A further compressed representation that requires fewer bits to store<br>Think of it like this: DAC does the heavy lifting of converting audio to a compact form, but the Transformer notices that even within this compact form, there are patterns (temporal dependencies, repetitions, predictable sequences) that can be exploited for additional compression.<br>This is similar to how traditional compression uses entropy coding after transform stages - except here it's a learned neural model that can capture much more complex statistical dependencies."</p>
<p>En attendant, le codec Opus est déjà une très bonne solution : <a href="https://opus-codec.org/downloads/.">https://opus-codec.org/downloads/.</a></p>
<p>Autre projet de Bellard : <a href="https://textsynth.com/,">https://textsynth.com/,</a> un serveur de LLM !<br>------<br>Je lis et relis <a href="https://news.ycombinator.com/item?id=42897856.">https://news.ycombinator.com/item?id=42897856.</a> Il y a quelque chose à faire.<br>------<br>On peut maintenant convertir un livre entier en audio avec kokoro : <a href="https://claudio.uk/posts/epub-to-audiobook.html">https://claudio.uk/posts/epub-to-audiobook.html</a></p>
<p><b>2025-10-03</b></p>
<p>Grosse fatigue. Short hearing loss right hand side. Je continue de prépare la présentation Youtube Métadata mais la gestion des multiples versions des scripts m'épuise. Il faut changer de méthode. Je tente une vidéo mais m'empêtre dans des explications sans fin.</p>
<p><b>2025-10-02</b></p>
<p>Script (Claude) pour visualiser les conversations ChatGPT avec leur date de création.</p>
<p>Oublier un peu l'accumulation de fichiers et se concentrer sur les compétences de résolution de problèmes avec tous les outils à notre disposition.</p>
<p>Quand on y réfléchit, le chemin qu'on prend pour arriver à un résultat peut être très alambiqué, il y a toutes les fausses pistes, les prompts qui ne donnent rien, les scripts ou les prompts que l'on réutilise, que l'on passe à une IA, puis à une autre, sans résultat tout de suite utilisable, ou parfois juste un peu à coté de la plaque.</p>
<p>Je commence à planifier les étapes de la restitution du projet "YouTube métadata" (Excalidraw).</p>
<p>Découverte (JB) de Stéphane Mallat. Coup de foudre. J'écoute tout ce que je peux trouver sur lui.<br><a href="https://www.radiofrance.fr/franceculture/podcasts/la-science-cqfd/stephane-mallat-la-palme-d-ondes-1077850">https://www.radiofrance.fr/franceculture/podcasts/la-science-cqfd/stephane-mallat-la-palme-d-ondes-1077850</a></p>
<p><b>2025-10-01</b></p>
<p>J'essaie de retracer le workflow de mon projet "YouTube metadata retrieval and analysis". Je cherche les premières conversations en espérant que ce soit bien sur Claude ou ChatGPT. Ça semble être le cas. Difficile de s'y retrouver.</p>
<p>Pour ChatGPT, j'exporte mes données et ouvre ensuite chat.html, dans lequel je peux faire une recherche par mots-clés. Normalement sur la version en ligne je devrais avoir un outil de recherche comme dans Claude, mais il n'apparaît pas sur ma version de ChatGPT, ce qui est bizarre. En plus de chat.html, ChatGTP propose un autre fichier (conversations.json) dans lequel les dates sont au format Unix epoch format (seconds since January 1, 1970, UTC).</p>
<p>Pour Claude version web, je peux utiliser leur boite de recherche, mais ça cherche uniquement les TITRES de conversations, pas leur contenu. Je fais donc également un export de mes données et j'obtiens entre autres un fichier conversations.json que j'ouvre avec Sublime Text et que je peux parser manuellement. Ce n'est pas très pratique alors je demande à Claude de me faire un script qui génère une page HTML comme pour ChatGPT. Ça marche nickel après quelques itérations.</p>
<p>Projet "YouTube metadata retrieval and analysis" historique</p>
<p>2024-10-30 ChatGPT : YouTube metadata (last modif. 2025-01-26)<br>2024-12-09 Claude : Aggregate YouTube Channel Titles from JSON<br>2024-12-11 Claude : YouTube Channel Video Scraper<br>2025-09-28 ChatGPT : Combine scripts and classify trends<br>2025-09-28 Claude : YouTube video download error<br>2025-09-30 Gemini CLI session</p>
<p><b>2025-09-30</b></p>
<p>How to download and open a .parquet file in ipython repl using uv (ubuntu):</p>
<p><pre><code>uv init parquet
cd parquet
uv add ipython pandas pyarrow
wget https://huggingface.co/datasets/ylecun/mnist/resolve/main/mnist/test-00000-of-00001.parquet -O mnist-test.parquet
ipython
import pandas as pd
df = pd.read_parquet('mnist-test.parquet')
print(df.head())
print(df.columns)
print(df.describe())</code></pre></p>
<p>Je demande à Claude de créer un convertisseur .epub vers .azw3, ce qu'il fait (epub_to_azw3.py). Le script a besoin que Calibre soit installé pour fonctionner.</p>
<p><a href="https://www.youtube.com/watch?v=Q7mS1VHm3Yw">https://www.youtube.com/watch?v=Q7mS1VHm3Yw</a> (Jodie Burchell – Build a Semantic Book Recommender)</p>
<p>J'installe Opencode (curl -fsSL <a href="https://opencode.ai/install">https://opencode.ai/install</a> | bash). Petit essai rapide, mais à priori Opencode est beaucoup moins intuitif et efficace que Gemini CLI.</p>
<p>Nouvelle session incroyable sur Google CLI pour mon projet "youtube metadata retrieval and analysis". Après 2h de 'pilotage', j'obtiens 2 scripts qui tiennent la route. Incroyable ce que ça marche bien. Le second script permet entre autres de lister tous les modèles proposés par une API. Chez Mistral j'ai cru voir 2 modèles faisant de l'OCR. J'utilise aussi openrouter qui propose plusieurs modèles gratuits parmi les dizaines proposés via leur API.</p>
<p><b>2025-09-29</b></p>
<p>Le taux de transfer en écriture sur ma carte microSD branchée avec un lecteur de carte USB3 est assez médiocre (env. 60 Mo/sec). Pas de changement si je formatte la carte en NTFS au lieu de ExFAT. Le taux de transfer avec un disque SSD et son adaptateur SATA-USB3 est bien meilleur : env. 350 Mo/sec en lecture comme en écriture.</p>
<p>La lecture de <a href="https://simonwillison.net/search/?q=translation">https://simonwillison.net/search/?q=translation</a> donne :<br>- <a href="https://news.ycombinator.com/item?id=42897856">https://news.ycombinator.com/item?id=42897856</a> (translation workflow)<br>- <a href="https://www.youtube.com/watch?v=eC5fqHEzzWs">https://www.youtube.com/watch?v=eC5fqHEzzWs</a> (text processing with .strip())</p>
<p>ChatGPT history : essai de fusionner et dédupliquer le contenu de plusieurs fichiers JSON de mon historique sur ChatGPT. Ne fonctionne pas.</p>
<p>Sortie de Claude Sonnet 4.5 (<a href="https://www.anthropic.com/news/claude-sonnet-4-5).">https://www.anthropic.com/news/claude-sonnet-4-5).</a></p>
<p>Je mets à jour LLM (uv tool upgrade llm) et constate que tous les plugins ont disparu ! Sur le sujet voir : <a href="https://news.ycombinator.com/item?id=44110584">https://news.ycombinator.com/item?id=44110584</a> et <a href="https://github.com/simonw/llm/issues/575.">https://github.com/simonw/llm/issues/575.</a> Il semblerait que Simon n'a pas corrigé le problème.</p>
<p>Dépoussiérage Voxtral script (fonctionne mais modèle ultra bridé).</p>
<p>Je modifie un script "autoencoder with MNIST dataset" avec Claude Sonnet 4.5 et ça fonctionne.</p>
<p><b>2025-09-28</b></p>
<p>Youtube metadata analysis scripts. Essai de les combiner en un seul avec un fichier .csv en entrée contenant une liste de chaînes YouTube (ChatGPT : "Combine scripts and classify trends") mais résultats inconsistants d'un run à l'autre. Utiliser RAG ?</p>
<p><b>2025-09-27</b></p>
<p><a href="https://www.youtube.com/watch?v=0OUODPRgPl8">https://www.youtube.com/watch?v=0OUODPRgPl8</a> (10+ tools to use ai in the terminal)<br><a href="https://www.youtube.com/watch?v=rGz0r8VaYCc">https://www.youtube.com/watch?v=rGz0r8VaYCc</a> (Jodie Burchell Real Python)<br><a href="https://www.youtube.com/watch?v=iRqpsCHqLUI">https://www.youtube.com/watch?v=iRqpsCHqLUI</a> (Jodie Burchell on LLMs for Devs)<br><a href="https://crawshaw.io/blog/programming-with-llms">https://crawshaw.io/blog/programming-with-llms</a> (David Crawshaw)</p>
<p><b>2025-09-26</b></p>
<p>Je désinstalle zsh et oh-my-zsh (Claude) pour l'instant.</p>
<p>Refresher sur llamacpp, qui ne veut plus se lancer depuis son répertoire en faisant 'llama-cli -m modele.gguf' comme avant. Solution :</p>
<p><pre><code># Download the latest llamacpp precompiled binaries
# Unzip and stick everything in (for example) $HOME/llamacpp/
# Add the build dir to your PATH
echo 'export PATH="$HOME/llamacpp/:$PATH"' >> ~/.bashrc
source ~/.bashrc
# Launch a model
llama-cli -m path_to/model.gguf</code></pre></p>
<p>EDIT : manip ci-dessus inutile si on fait <code>./llama-cli -m modele.gguf</code> dans le répertoire où llamacpp est installé</p>
<p>Retour à la vidéo de Willison sur son outil LLM (<a href="https://www.youtube.com/watch?v=QUXQNi6jQ30).">https://www.youtube.com/watch?v=QUXQNi6jQ30).</a> Vers 28'35", je fais une copie d'écran de son exemple de script en bash qui résume les thèmes des commentaires d'un sujet de Hacker News et je demande à Claude de transcrire le texte de l'image, ce qu'il fait sans aucune erreur. Je colle le code dans un fichier (hn_summarizer.sh), auquel je donne les droits d'exécution (cmod +x hn_summarizer.sh), puis je remplace 'haiku' par 'groq/openai/gpt-oss-20b', mon modèle par défaut dans llm. Ensuite je choisis un sujet au hasard dans Hacker News et clique sur le lien pour afficher les commentaires (ex. <a href="https://news.ycombinator.com/item?id=45384653).">https://news.ycombinator.com/item?id=45384653).</a> Je copie le numéro d'id (45384653) et lance le script de Willison en faisant ./hn_summarizer.sh 45384653. J'obtiens un résumé des thèmes abordés. Avec la version gratuite de mon modèle (fenêtre contextuelle limitée) je ne peux pas choisir de sujets qui ont trop de commentaires (30 maxi je dirais). Mais je peux changer de modèle et mettre par exemple 'openrouter/meta-llama/llama-3.3-70b-instruct:free'.<br>Post de Simon sur le sujet : <a href="https://til.simonwillison.net/llms/claude-hacker-news-themes">https://til.simonwillison.net/llms/claude-hacker-news-themes</a></p>
<p>A faire : embeddings @ 41'11"</p>
<p><b>2025-09-25</b></p>
<p>Essais de conversion et de reconstruction d'un document PDF de 60 pages en Word. Catherine convertit le doc avec Acrobat Pro mais mise en page "fragile", surtout si on doit modifier le document ultérieurement. J'essaie avec différentes IA (Gemini, Mistral, Claude, ChatGPT) de passer du texte brut copié à partir du PDF à du markdown propre et structuré. C'est ChatGPT qui donne le meilleur résultat, au moins pour le début du document.</p>
<p>Prompt : <code>This text is a raw copy from a PDF document. Reformat it as readable markdown. Do not alter its content. Do not summarize. Do not translate.</code></p>
<p>Ensuite je demande à Claude de créer un script qui convertit le markdown généré par ChatGPT en Word et ça marche. Mon intuition me dit que le fichier Word ainsi généré est beaucoup plus fiable que le fichier issu de la conversion avec Acrobat. Cependant cette méthode induit encore de trop nombreuses approximations pour être réellement fiable.</p>
<p>Je me replonge dans Willison's LLM. J'installe plusieurs plugins : llm-cmd, llm-command-r, llm-ollama, llm-groq, llm-openrouter, llm-mistral. Je crée un compte sur <a href="https://openrouter.ai/.">https://openrouter.ai/.</a> Je visionne la vidéo de Mark Needham sur LLM : <a href="https://www.youtube.com/watch?v=aQuuJuCa0VM.">https://www.youtube.com/watch?v=aQuuJuCa0VM.</a></p>
<p>Commandes intéressantes :<br>llm 'Who is Simon Willison?' > output.txt (écrit le résultat dans un fichier)<br>cat /etc/*-release | llm -s "Tell me about my operating system" (pipe le résultat de la commande dans LLM et répond au prompt)</p>
<p><b>2025-09-24</b></p>
<p>On est peu à peu tenté de refiler aux IA des trucs que l'on juge difficiles ou infaisables, même pour elles. Je donne à Gemini (interface web) un texte brut sans mise en forme issu d'un copier-coller sauvage d'un PDF. Prompt : "Produis une version fidèle et restructurée en markdown de ce document en prenant soin de faire apparaitre les titres de section et les paragraphes. Ne le traduis pas." Gemini s'exécute, puis je ne sais pas ce qui se passe, Gemini bugue et je perds tout.</p>
<p>J'installe zsh et oh-my-zsh selon les instructions de Claude.</p>
<p>Je télécharge l'appli web "gpx-map-filter" que j'avais générée avec Google AI Studio l'autre jour et demande à Gemini CLI de la faire fonctionner en local. Gemini CLI me dit qu'il faut créer une clé API sur Google Cloud. Je lui réponds que je n'en ai pas. Il me donne alors une solution sans avoir recours à une clé API ! Il faut installer node et lancer un serveur en tapant "npn run dev". Ça fonctionne. Il faudrait modifier l'appli pour ajouter plusieurs fonctionnalités.</p>
<p><b>2025-09-20</b></p>
<p>Fichiers GPX : ChatGPT, le retour ! Après m'être perdu avec Claude et ses scripts interminables, une requête à ChatGPT produit un script très simple d'une soixantaine de lignes qui fait le taf sans essayer de centraliser tous les points des GPX dans un gros dataframe : <a href="https://chatgpt.com/c/68ce6b64-0f08-8330-a677-8b89b53fe998.">https://chatgpt.com/c/68ce6b64-0f08-8330-a677-8b89b53fe998.</a> Leçon à retenir pour l'avenir : le compliqué/complexe n'est pas forcément mieux que le simple.</p>
<p><b>2025-09-18</b></p>
<p>Je reconstitue partiellement la démarche du projet "docx-images" avec les 3 sessions de Gemini CLI que je regroupe dans un seul fichier texte.</p>
<p>Je me replonge dans l'idée de produire des fichiers GPX "propres". Je perfectione un outil en ligne de commande généré sur Claude. Le script finit par être assez long (1000+ lignes de code) et n'est pas foufou. Certaines fonctions du menu ne fonctionnent pas correctement. Je génère d'autres scripts "from scratch" jusqu'à en perdre la tête. C'est le problème de ces outils. Il faut être hyper-organisé sinon on peut se noyer dans les scripts.</p>
<p><b>2025-09-16</b></p>
<p>Je poursuis mon projet de retirer/remettre les images avec des documents. J'utilise le script d'hier soir (qui fonctionnait avec des documents .odt) comme base pour Gemini et lui demande d'en faire une version qui fonctionnerait avec des fichiers Word. Cette fois ça marche après seulement 2-3 itérations (docx_image_manager.py). Mais le plus fort c'est que j'essaie ensuite avec le fichier d'un client contenant 423 images et ça marche ! Je n'en reviens pas. Je pensais vraiment qu'avec un gros fichier complexe ça ne marcherait pas. Il faudrait que j'arrive à retracer tout la démarche. Je crois qu'au début je suis parti d'un script généré par Claude.</p>
<p><b>2025-09-15</b></p>
<p>J'essaie d'installer Gemini CLI dans Windows Powershell mais je n' y arrive pas, alors je l'installe sur WSL <code>npm install -g @google/gemini-cli</code>. Pour se loguer avec son compte Google dans WSL, il faut taper <code>gemini nobrowser=TRUE</code> (impossible de retrouver la source de cette info).</p>
<p>Je fais travailler Gemini CLI sur un problème assez ardu. Créer un script qui prend un .docx avec des images en entrée, retire toutes les images et génère un fichier .docx sans images (qui ainsi sera "léger" et pourra être traduit). Puis dans un second temps un second script reprend le fichier traduit (sans images) et remet toutes les images à leur place. Pour l'instant mon script n°1 arrive à retirer les images, mais le n°2 n'arrive pas à les remettre. Gemini CLI a bossé comme un dingue pour y arriver, sans succès. C'était fascinant comme session. Je lui ai dit d'utiliser uv (ex. <code>uv run script.py</code>) et il l'a fait. Il s'est arrêté 2-3 fois et je lui ai dit "continue" et il a continué !</p>
<p>Dans un premier temps je lui demande de créer des "placeholders" numérotés "image1.jpg, image2.jpg, etc.", ce qu'il fait, mais ensuite je me rends compte que ce n'est pas la bonne méthode. Je lui demande alors d'extraire le "squelette XML" du docx. Là il parvient à retirer les images sans toucher au code XML. Ça donne un fichier Word sans images avec des sortes de cadres vides à la place, comme quand il manque une image sur un site internet. Je crois que passer par le XML qui est constitutif des fichiers Word en .docx est la bonne voie, mais Gemini a vraiment beaucoup de mal à gérer le truc. Je crois que la manière dont un fichier Word est encodé est un vrai cauchemar, même pour une IA.</p>
<p>Olivier suggère d'essayer la même manip avec le format Libre Office (.odt). Le soir je reprends tout depuis le début avec un fichier ODT contenant du texte et des images. Je demande à Gemini de créer 2 scripts : un qui enlève les images et génère le doc sans images et un second script qui prend le doc sans images et les remet. J'atteins bientôt la limite du modèle pro et n'ai d'autre choix que de continuer avec gemini-2.5-flash. Je continue et ça marche ! Chose surprenante, les scripts générés ne sont pas si longs que ça (beaucoup moins que pour Word). Je contine encore un peu et regroupe les 2 scripts en un seul avec un menu basique : 1. retirer les images, 2. remettre les images. Gemini-2.5-flash semble bien marcher pour ce genre de petites modifs (odt_image_manager.py).</p>
<p>Je me rends compte que les outils comme Gemini CLI et Claude Code sont l'aboutissement de toutes les avancées dont on entend parler depuis la sortie de ChatGPT : chain-of-thought prompting, RAG, fonction calling, tool use, augmentation de la taille de la fenêtre contextelle, agents autonomes, MCP... Tout ça enfin mis en oeuvre de manière cohérente. Je demande à ChatGPT s'il est d'accord avec mon constat et il me répond comme souvent, en me caressant dans le sens du poil :<br><code>Tu touches un point très juste 👍 : des outils comme Gemini CLI et Claude Code incarnent une sorte de "synthèse appliquée" de toutes les briques d’innovation accumulées dans le domaine des LLM depuis fin 2022. Au début, on avait "juste" ChatGPT comme assistant conversationnel. Puis, étape par étape, des concepts et technologies se sont empilés pour transformer les LLM en véritables systèmes intelligents, interactifs et spécialisés</code>.</p>
<p><b>2025-09-14</b></p>
<p>Pour utiliser VSCode dans un répertoire sans installer Python sur la machine : <code>uv init, uv add ipykernel</code> (pour les jupyter notebooks) et c'est parti.</p>
<p>Je regarde ce que devient Willison's LLM tool (<a href="https://llm.datasette.io/en/stable/).">https://llm.datasette.io/en/stable/).</a> Je ne peux m'empêcher de penser que Claude Code et Gemini CLI s'en sont grandement inspirés.</p>
<p>Pyodide est un outil épatant qui permet d'exécuter du code Python dans un navigateur (<a href="https://pyodide.org/en/stable/console.html).">https://pyodide.org/en/stable/console.html).</a></p>
<p><b>2025-09-13</b></p>
<p>Je fais mumuse avec Gemini CLI depuis 2 jours et c'est vraiment totalement bluffant ce que ça peut faire. Ce qui est dingue c'est que Gemini CLI en mode gratuit permet de vraiment travailler (60 requests/min and 1,000 requests/day). Je lui ai donné l'accès à un répertoire rempli de scripts plus ou moins récents permettant de manipuler les fichier GPX et lui ai demandé d'analyser les fichiers. Il a tout de suite identifié lesquels étaient les plus aboutis et les a ensuite perfectionnés tout en vérifiant que ça marchait sur des vraies données. On peut lui demander n'importe quoi, il code, il réfléchit, il exécute en bash, la totale ! Et il est capable de gérer un contexte de 1 million de tokens ! Selon Gemini, le script le plus abouti de mon test était un script écrit par Claude.</p>
<p><b>2025-09-02</b></p>
<p>Demande d'un client pour une transcription de 5h d'enregistrement. Groq toujours au top pour transcrire les fichiers audio, à condition de réduire leur taille au préalable avec ffmpeg. Pour obtenir une transcription "diarisée" je donne la transcription brute à Claude avec le prompt suivant :<br><code>Le texte ci-joint est la transcription brute d'un entretien entre 2 interlocuteurs. Peux-tu améliorer cette transcription en veillant à séparer les prises de paroles et en prenant soin de retirer tous les tics de language, répétitions inutiles, etc., tout restant fidèle aux propos tenus? Le texte final devra être fluide et agréable à lire." Le résultat est bluffant. Le modèle parvient à identifier les intervenants et à découper leur prises de paroles respectives à partir de la transcription brute.</code></p>
<p><b>2025-09-01</b></p>
<p>Retour au boulot ce matin. Nous avons reçu une nouvelle demande de transcription d'enregistrements et je me replonge sans transition dans Whisper et autres joyeusetés en matière de speech-to-text. Je teste Voxtral (voxtral-mini-latest), le modèle speech-to-text de Mistral. Ça marche, mais la transcription est tronquée. Groq semble toujours fonctionner. Ils ont retiré un modèle (distil-whisper) de leur liste.</p>

</main>

</body>
</html>
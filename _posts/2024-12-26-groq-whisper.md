## Groq Whisper

[OpenAi Whisper](https://openai.com/index/whisper/) est un modèle de reconnaissance automatique de la parole entraîné sur 680 000 heures de données audio multilingues. Ce système permet d'automatiser la transcription d'un enregistrement sonore contenant de la parole humaine. Ses applications sont variées et vont de la simple transcription (avec ou sans traduction) à la génération de sous-titres.

L'année dernière pour les besoins d'un projet, j'avais créé [un jupyter notebook](https://gist.github.com/sebington/a5a402a12a525f7e0efa9c972f45ba58) permettant d'automatiser la transcription et la génération de sous-titres pour un ensemble de fichiers audio ou vidéo (*batch transcription*). J'avais ensuite retravaillé mon notebook pour faire en sorte de transcrire des fichiers source de langues différentes. Il fallait que les fichiers à transcrire soient préalablement renommés en adoptant une convention pour la langue (par exemple "en_fichier_1.mp3", "fr_fichier_2.mp3", etc.). Cela évitait à Whisper d'effectuer une détection automatique de la langue, opération pas toujours fiable si plusieurs langues cohabitent au sein d'un même enregistrement ou si les 30 premières secondes d'un enregistrement ne contiennent pas de discours intelligible (ex. bruit ou musique). 

J'avais ensuite découvert [Faster-whisper](https://github.com/SYSTRAN/faster-whisper), une version de Whisper plus rapide, elle même basée sur [CTranslate2](https://github.com/OpenNMT/CTranslate2/), une bibliothèque Python écrite en C++ permettant une inférence plus efficiente des modèles basés sur Transformer. En faisant tourner [mon notebook faster-whisper](https://gist.github.com/sebington/7cda2fec1302aab6f30048f207a5efcb) sur Google Colab, j'obtenais des temps d'inférence tout à fait corrects, beaucoup plus courts qu'avec la version d'origine de Whisper. Mais les choses évoluent très vite dans le monde de l'IA. Il est actuellement impossible d'installer faster-whisper sur mon PC (même en utilisant [uv](https://docs.astral.sh/uv/)), ni de le faire tourner sur Google Colab, qui crashe systématiquement. Pas grave me direz-vous, parce que maintenant on a Groq.

L'[API de Groq](https://console.groq.com/docs/overview), gratuite pour un usage modéré, permet entre autres de transcrire des fichiers audio ou vidéo (mp3, mp4, mpeg, mpga, m4a, wav, webm) en un temps record, à condition que la taille des fichiers envoyés à Groq ne dépasse pas 25 Mo. Le hic, c'est qu'à ma connaissance Groq ne permet pas de générer des sous-titres, ni de faire des transcriptions par lots. J'ai donc adapté mon code prévu pour fonctionner avec faster-whisper à Groq. Avec l'aide de Claude 3.5 Sonnet, j'ai à mis à jour [mon notebook](https://gist.github.com/sebington/c2e6c6ef7bb32fb8bcb1f2cd062b4bdc) pour qu'il soit compatible avec Groq.

La différence principale c'est qu'avec Groq, la récupération de chaque segment de la transcription se fait différemment. Avec Faster-whisper, on accédait aux segments en utilisant la notation `segment.start`, ce qui indique que `segment` était un objet ou une instance de classe avec des attributs. Avec Groq, on accède aux segments en utilisant une syntaxe plus classique, propre aux dictionnaires Python : `segment['start']`.

J'ai ensuite regroupé le code pour transcrire un fichier unique dans [un script en python](https://gist.github.com/sebington/7b20c57bf80cf3b91aea673089aab07e), ce qui évite de devoir exécuter les cellules du notebook les unes après les autres. J'ai ensuite essayé de rendre le script plus convivial et plus abouti en demandant à Claude certaines améliorations (choix du fichier à transcrire avec la souris, choix du modèle de Whisper avec une case à cocher, gestion des erreurs, etc.). Claude m'a proposé [un truc assez chiadé](https://gist.github.com/sebington/e9f98e7a7e20478817fa2be08ab4deb4) qui, après quelques itérations, semble tenir la route.

Cependant j'avoue avoir une préférence pour le code de départ, plus basique mais fonctionnel et facile à comprendre. La version "production-ready" demandée à Claude est super, mais elle est moins "pédagogique". Cela m'a d'ailleurs fait penser à la démarche inverse. Pourquoi ne pas demander à Claude de produire une version la plus courte possible ? Claude s'est exécuté et a généré [une version substanciellement plus compacte](https://gist.github.com/sebington/eb4aa8ebbc01a6a498792aaa87ff6d67). Ce qui est intéressant, c'est que cette dernière version fait appel à des modules et des algorithmes différents, notamment pour générer le timecode propre aux sous-titres.

En conclusion, l'essor des IA génératives et leur extrême facilité à générer du code permet pas mal d'expérimentations. On peut créer un script à partir de rien, recycler du code poussiéreux, générer des versions plus conviviales ou demander au modèle d'optimiser du code en lui donnant par exemple une contrainte de longueur ou de compacité. L'arrivée des IDE dopés à l'IA comme [Cursor](https://www.cursor.com/) et [Windsurf](https://codeium.com/windsurf) ouvre des possibilités infinies qui vont bien au delà de ces modestes expérimentations. Mais est-ce que le plaisir de comprendre restera le même ?

